# Qualitiative Evaluation of Navigation Models

This repo is fork of the original repo on [navigation models](https://github.com/robodhruv/visualnav-transformer) - GNM, ViNT, NoMaD - built by Dhruv Shah et al. You can find the original readme file [here](./original_readme.md). 



To set up the development environment, thoroughly follow the instructions provided in the original readme file. 

This repo just has additional code adapted from the source to qualitatively evaluate the predictions produced by navigation models. This contain few extra files namely `evaluate_goal_based_navigation.py`, `extract_frames.py` `visualize_all_trajectories.py`, `visualize_trajectory.py` files. All these files can be found in [src](./deployment/src) folder within [deployment] directory. 

To qualitatively evaluate predictions using a manually collected video of a trajectory, you need to do the following - 

1. Download `nomad.pth` checkpoint from [here](https://drive.google.com/drive/folders/1a9yWR2iooXFAqjQHetz263--4_2FFggg)
2. Shoot a video using mounted camera or a mobile phone. It would be ideal if the frame rate of the camera within 15 FPS. 
3. use [`extract_frames.py`](./deployment/src/extract_frames.py) file to extract the image frames. Frames will be numbered from `0.jpg`, `1.jpg`,..., `n-1.jpg` where `n` is the number of frames in video and will be saved in the same directory as of the video for each trajectory video. These images will be saved in a directory - `<video_name>_imageframes`.
4. Move those videos to a new directory (for example in `./datasets/mobile_videos/processed` folder)
5. Use [`evaluate_goal_based_navigation.py`](./deployment/src/evaluate_goal_based_navigation.py) to produce predictions which will be saved as numpy file in the same directory where the images of the trajectory for the video exists by changing the `trajectories_folder` variable in line `219` to this new folder containing folders of trajectories (for exmaple here `./datasets/mobile_videos/processed`). 
6. Once these predictions are generated, use [`visualize_all_trajectories`](./deployment/src/visualize_all_trajectories.py) to visualize the waypoints generated by the model, which will be saved in `vis_outputs` directory within the directory of the trajectoy by changing the `base_path` variable to this new file containing trajectories of images (for exmaple here - `./datasets/mobile_videos/processed`). This file uses [`visualize_trajectory.py`](./deployment/src/visualize_trajectory.py) for visualizing each  of the trajectory

To evaluate on some dataset, please follow the instruction in the original readme file detailing how to process different types of datsets and create a trajectory folders and then follow the step 4 onwards. 

Stay tuned for further updates. 

